# ü§ñ Dostoevsky Neural Bot (LoRA + Mistral 7B)

Telegram-–±–æ—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –º–æ–¥–µ–ª–∏ [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1), –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π —Å –ø–æ–º–æ—â—å—é LoRA –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö –§.–ú. –î–æ—Å—Ç–æ–µ–≤—Å–∫–æ–≥–æ.

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

dostoevsky-texts/
‚îú‚îÄ‚îÄ bot.py # Telegram-–±–æ—Ç —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤
‚îú‚îÄ‚îÄ train.py # –°–∫—Ä–∏–ø—Ç –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ prepare_dataset.py # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îú‚îÄ‚îÄ dostoevsky_dataset.jsonl # –û–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL
‚îú‚îÄ‚îÄ lora-mistral-dostoevsky/ # –ö–∞—Ç–∞–ª–æ–≥ —Å LoRA-—á–µ–∫–ø–æ–π–Ω—Ç–∞–º–∏
‚îÇ ‚îú‚îÄ‚îÄ checkpoint-500/
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ project_structure.txt # –°–Ω–∏–º–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ (—á–µ—Ä–µ–∑ tree)
‚îú‚îÄ‚îÄ .gitignore # Git-–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ñ–∞–π–ª—ã
‚îî‚îÄ‚îÄ README.md # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (—ç—Ç–æ—Ç —Ñ–∞–π–ª)

---

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞

> ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è Linux-—Å–∏—Å—Ç–µ–º–∞ —Å CUDA 11.8+, Python ‚â• 3.10 –∏ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞ —Å ‚â•12 GB VRAM

```bash
# 1. –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone git@github.com:Crewar-wq/neuro.git
cd neuro  # –ª–∏–±–æ cd dostoevsky-texts –µ—Å–ª–∏ —Ç—ã —É–∂–µ —Ç–∞–º

# 2. –°–æ–∑–¥–∞—ë–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python3 -m venv training-env
source training-env/bin/activate

# 3. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install --upgrade pip
pip install -r requirements.txt
–ï—Å–ª–∏ —Ñ–∞–π–ª–∞ requirements.txt –Ω–µ—Ç, –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Ä—É—á–Ω—É—é:

pip install transformers datasets peft accelerate bitsandbytes aiogram
üß† –û–±—É—á–µ–Ω–∏–µ (LoRA Fine-tuning)

python prepare_dataset.py    # (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–æ–±—Ä–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç)

python train.py              # –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
‚úÖ –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ lora-mistral-dostoevsky/checkpoint-*

ü§ñ –ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞
–£–∫–∞–∂–∏ —Å–≤–æ–π Telegram API —Ç–æ–∫–µ–Ω –≤ bot.py:

python
API_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN"
–ó–∞–ø—É—Å—Ç–∏ –±–æ—Ç–∞:

python bot.py
–ë–æ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç inference –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è.

üí° –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: mistralai/Mistral-7B-Instruct-v0.1

–û–±—É—á–µ–Ω–∏–µ: LoRA —Å 4-bit –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ–º (bitsandbytes)

–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è: max_length=512, padding=eos_token

–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤ (checkpoint-*)

–û—Ç–≤–µ—Ç—ã –æ—á–∏—â–∞—é—Ç—Å—è –æ—Ç –∞–≤—Ç–æ–¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ —à–∞–±–ª–æ–Ω–∞–º (User:, Bot:)

üì¶ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PeftModel.from_pretrained –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ LoRA –≤–µ—Å–æ–≤

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω—É–∂–µ–Ω CUDA GPU, –∏–Ω–∞—á–µ —Å–∏–ª—å–Ω–æ –∑–∞–º–µ–¥–ª—è–µ—Ç—Å—è

Telegram-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —á–µ—Ä–µ–∑ aiogram v3+ (async)
